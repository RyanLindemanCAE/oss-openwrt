--- /dev/null
+++ b/drivers/mtd/nand/ath79_nand.c
@@ -0,0 +1,923 @@
+/*
+ * Atheros AR71XX/AR724X/AR913X NAND controller driver
+ *
+ * Copyright (c) 2012 The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+ * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+ */
+
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/ioport.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+#include <linux/dma-mapping.h>
+#include <linux/err.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include <linux/bitops.h>
+#include <linux/jiffies.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/nand_ecc.h>
+#include <linux/mtd/partitions.h>
+#include <asm/mach-ath79/ar71xx_regs.h>
+
+/* module related macros */
+#define DRV_NAME	"ath79-nand"
+#define DRV_VERSION	"1.0"
+#define DRV_AUTHOR	"Qualcomm-Atheros Inc."
+#define DRV_DESC	"AR71xx/AR9xxx Qualcomm-Atheros NAND FLash Controller driver"
+
+/* misc macros */
+#define AR934X_NAND_STATUS_RETRY	1000
+#define DDR_WB_FLUSH_USB_ADDRESS	0x180000a4
+
+/* static data for ath79_nand driver configuration */
+static const char *ath79_nand_part_probes[] __initdata =
+    { "cmdlinepart", "RedBoot", NULL };
+
+static struct mtd_partition ath79_nand_partitions[] = {
+	{
+	 .name = "nand0",
+	 .offset = 0,
+	 .size = MTDPART_SIZ_FULL,
+	 },
+};
+
+static struct nand_ecclayout ath79_nand_oob_64 = {
+	.eccbytes = 28,
+	.eccpos = {
+		   20, 21, 22, 23, 24, 25, 26, 27,
+		   28, 29, 30, 31, 32, 33, 34, 35,
+		   36, 37, 38, 39, 40, 41, 42, 43,
+		   44, 45, 46, 47},
+	.oobfree = {
+		    {.offset = 4,
+		     .length = 16},
+		    {.offset = 48,
+		     .length = 16}
+		    }
+};
+
+typedef struct {
+	uint8_t		vid,
+				did,
+				b3,
+				addrcyc,
+				small,
+				spare;	// for small block;
+	uint16_t	pgsz;	// for small block
+	uint32_t	blk;	// for small block
+} ath_nand_vend_data_t;
+
+ath_nand_vend_data_t ath_nand_arr[] = {
+	{ 0x20, 0xda, 0x10, 5, },	// NU2g3B2D
+	{ 0x20, 0xf1, 0x00, 4, },	// NU1g3B2C
+	{ 0x20, 0xdc, 0x10, 5, },	// NU4g3B2D
+	{ 0x20, 0xd3, 0x10, 5, },	// NU8g3F2A
+	{ 0x20, 0xd3, 0x14, 5, },	// NU8g3C2B
+	{ 0xad, 0xf1, 0x00, 4, },	// HY1g2b
+	{ 0xad, 0xda, 0x10, 5, },	// HY2g2b
+	{ 0xec, 0xf1, 0x00, 4, },	// Samsung 3,3V 8-bit [128MB]
+	{ 0x98, 0xd1, 0x90, 4, },	// Toshiba
+	{ 0xad, 0x76, 0xad, 5, 1, 16, 512, 16 << 10 },	// Hynix 64MB NAND Flash
+	{ 0xad, 0x36, 0xad, 5, 1, 16, 512, 16 << 10 },	// Hynix 64MB NAND Flash
+	{ 0x20, 0x76, 0x20, 5, 1, 16, 512, 16 << 10 },	// ST Micro 64MB NAND Flash
+};
+
+#define NUM_ARRAY_ENTRIES(a)	(sizeof((a)) / sizeof((a)[0]))
+#define NUM_ATH_NAND		NUM_ARRAY_ENTRIES(ath_nand_arr)
+
+/* ath nand controller DMA descriptor */
+typedef struct {
+	uint32_t addr;
+	uint32_t len;
+} ath79_nand_dma_descr;
+
+/* ath nand priv info */
+typedef struct {
+	struct nand_chip nand;
+	uint32_t nf_ctrl;
+	uint32_t command;
+	uint32_t curr_data;
+	uint32_t data_index;
+	uint8_t *page_buf;
+	void __iomem *io_base;
+	void __iomem *ddr_io_addr;
+	ath79_nand_dma_descr *dma_descr_virtaddr;
+	dma_addr_t dma_descr_phyaddr;
+	struct device *dev;
+} ath79_nand_priv;
+
+/****************************************/
+/***** NAND chip internal functions *****/
+/****************************************/
+static int ath79_rw_oob(struct mtd_info *mtd, struct nand_chip *chip, int rw,
+			int page);
+
+static inline int ath79_oobbuf_is_dirty(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = mtd->priv;
+	uint8_t *p = chip->oob_poi;
+	int i;
+
+	for (i = 0; i < mtd->oobsize; i++) {
+		if (p[i] != 0xff)
+			return 1;
+	}
+
+	return 0;
+}
+
+static int ath79_page_no_ecc(struct mtd_info *mtd, int page)
+{
+	struct nand_chip *chip = mtd->priv;
+	uint8_t *p = chip->oob_poi;
+	int i;
+
+	ath79_rw_oob(mtd, chip, 1 /*read */ , page);
+
+	for (i = 0; i < mtd->ecclayout->eccbytes; i++) {
+		if (p[mtd->ecclayout->eccpos[i]] != 0xff)
+			return 0;
+	}
+
+	return 1;
+}
+
+static int ath79_nand_hw_init(ath79_nand_priv * ath79_priv)
+{
+	unsigned rddata;
+	void __iomem *tmp_io_addr;
+
+	// Put into reset
+	tmp_io_addr =
+	    ioremap(AR71XX_RESET_BASE + AR934X_RESET_REG_RESET_MODULE, 4);
+	rddata = ioread32(tmp_io_addr);
+	iowrite32(rddata | AR934X_RESET_NANDF, tmp_io_addr);
+	udelay(250);
+
+	iowrite32(rddata & (~AR934X_RESET_NANDF), tmp_io_addr);
+	udelay(100);
+
+	iounmap(tmp_io_addr);
+
+	iowrite32(AR934X_NAND_CMD_END_INT,
+		  ath79_priv->io_base + AR934X_NAND_REG_INT_MASK);
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+
+	// TIMINGS_ASYN Reg Settings
+	iowrite32(AR934X_NAND_TIMING_ASYN_SETTING,
+		  ath79_priv->io_base + AR934X_NAND_REG_TIMINGS_ASYN);
+	iowrite32(AR934X_NAND_TIME_SEQ_SETTING,
+		  ath79_priv->io_base + AR934X_NAND_REG_TIME_SEQ);
+
+	// NAND Mem Control Reg
+	iowrite32(0xff00, ath79_priv->io_base + AR934X_NAND_REG_MEM_CTRL);
+
+	return 0;
+}
+
+static int ath79_rw_oob(struct mtd_info *mtd, struct nand_chip *chip, int rw,
+			int page)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	int i, dmastatus, status = 0;
+	int dir, dma_ctrl;
+	dma_addr_t pa;
+
+	dir = rw ? DMA_FROM_DEVICE : DMA_TO_DEVICE;
+	pa = dma_map_single(NULL, chip->oob_poi, mtd->oobsize, dir);
+
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+	iowrite32((page << 16) | mtd->writesize,
+		  ath79_priv->io_base + AR934X_NAND_REG_ADDR0_0);
+	iowrite32((page >> 16) & 0x0ff,
+		  ath79_priv->io_base + AR934X_NAND_REG_ADDR0_1);
+	iowrite32(pa, ath79_priv->io_base + AR934X_NAND_REG_DMA_ADDR);
+	iowrite32(mtd->oobsize,
+		  ath79_priv->io_base + AR934X_NAND_REG_DMA_COUNT);
+
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ECC_OFFSET);
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ECC_CTRL);
+	iowrite32(ath79_priv->nf_ctrl | AR934X_NAND_CTRL_CUSTOM_SIZE_EN,
+		  ath79_priv->io_base + AR934X_NAND_REG_CTRL);
+	iowrite32(mtd->oobsize, ath79_priv->io_base + AR934X_NAND_REG_PG_SIZE);
+
+	dma_ctrl =
+	    AR934X_NAND_DMA_CTRL_DMA_START | AR934X_NAND_DMA_CTRL_DMA_BURST_3;
+
+	if (rw) {		// read OOB
+		iowrite32(dma_ctrl | AR934X_NAND_DMA_CTRL_DMA_DIR_READ,
+			  ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+		iowrite32(0x30006a,
+			  ath79_priv->io_base + AR934X_NAND_REG_COMMAND);
+		ath79_priv->data_index = 0;
+	} else {		// write OOB
+		iowrite32(0xff00, ath79_priv->io_base + AR934X_NAND_REG_MEM_CTRL);	// Remove write protect
+		iowrite32(dma_ctrl | AR934X_NAND_DMA_CTRL_DMA_DIR_WRITE,
+			  ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+		iowrite32(0x10804c,
+			  ath79_priv->io_base + AR934X_NAND_REG_COMMAND);
+	}
+
+	while ((ioread32(ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS) &
+		AR934X_NAND_CMD_END_INT) == 0) ;
+
+	status = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+	for (i = 0; i < AR934X_NAND_STATUS_RETRY && status != 0xff; i++) {
+		udelay(2);
+		status = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+	}
+	if (status != 0xff) {
+		dev_err(ath79_priv->dev,
+			"%s: NAND status error. Status = 0x%x\n", __func__,
+			status);
+		status = -EIO;
+	} else {
+		status = 0;
+	}
+
+	if (rw) {
+		nand_wait_ready(mtd);	// wait for ready pin for read OOB
+	} else {
+		status = chip->waitfunc(mtd, chip);	// check device status for write OOB
+		if (status & NAND_STATUS_FAIL) {
+			dev_err(ath79_priv->dev,
+				"%s: Write Failed. status = 0x%x\n", __func__,
+				status);
+			status = -EIO;
+		} else {
+			status = 0;
+		}
+	}
+
+	dmastatus = ioread32(ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+	for (i = 0; i < AR934X_NAND_STATUS_RETRY && !(dmastatus & 1); i++) {
+		udelay(5);
+		dmastatus =
+		    ioread32(ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+	}
+	if (!(dmastatus & 1)) {
+		dev_err(ath79_priv->dev, "%s: unfinished DMA. status = 0x%x\n",
+			__func__, dmastatus);
+		ath79_nand_hw_init(ath79_priv);
+		/* is this for killing unfinished DMA ??? */
+		iowrite32(1, ath79_priv->ddr_io_addr);
+		while (ioread32(ath79_priv->ddr_io_addr) & 1) ;
+		udelay(2);
+	}
+
+	dma_unmap_single(NULL, pa, mtd->oobsize, dir);
+
+	iowrite32(1, ath79_priv->io_base + AR934X_NAND_REG_FIFO_INIT);
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_FIFO_INIT);
+
+	return status;
+}
+
+static int ath79_rw_page(struct mtd_info *mtd, struct nand_chip *chip, int rw,
+			 uint8_t * buf, int len, int page)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	int status = 0;
+	int i, dir, dmastatus, ecc_enable, ecc_status;
+	int dma_ctrl, copy = 0;
+	dma_addr_t pa1, pa2 = 0;
+
+	dir = rw ? DMA_FROM_DEVICE : DMA_TO_DEVICE;
+
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+	iowrite32(page << 16, ath79_priv->io_base + AR934X_NAND_REG_ADDR0_0);
+	iowrite32((page >> 16) & 0x0ff,
+		  ath79_priv->io_base + AR934X_NAND_REG_ADDR0_1);
+	iowrite32(len, ath79_priv->io_base + AR934X_NAND_REG_DMA_COUNT);
+
+	dma_ctrl =
+	    AR934X_NAND_DMA_CTRL_DMA_START | AR934X_NAND_DMA_CTRL_DMA_BURST_3;
+
+	if (is_vmalloc_addr(buf)) {
+		if (!rw)
+			memcpy(ath79_priv->page_buf, buf, mtd->writesize);
+		pa1 =
+		    dma_map_single(NULL, ath79_priv->page_buf, mtd->writesize,
+				   dir);
+		copy = 1;
+	} else {
+		pa1 = dma_map_single(NULL, buf, mtd->writesize, dir);
+	}
+
+	if (!rw)
+		dev_dbg(ath79_priv->dev,
+			"%s: read %d, page 0x%x, size=0x%x, virt buffer %d\n",
+			__func__, rw, page, len, copy);
+
+	if ((len & mtd->writesize_mask) == 0) {
+		/* non-scatter-gather DMA mode */
+		iowrite32(pa1, ath79_priv->io_base + AR934X_NAND_REG_DMA_ADDR);
+		iowrite32(mtd->writesize + chip->ecc.layout->eccpos[0],
+			  ath79_priv->io_base + AR934X_NAND_REG_ECC_OFFSET);
+		iowrite32(AR934X_NAND_ECC_CORR_BITS(4),
+			  ath79_priv->io_base + AR934X_NAND_REG_ECC_CTRL);
+		iowrite32(ath79_priv->nf_ctrl | AR934X_NAND_CTRL_ECC_EN,
+			  ath79_priv->io_base + AR934X_NAND_REG_CTRL);
+		ecc_enable = 1;
+	} else {
+		/* scatter-gather DMA mode */
+		ath79_priv->dma_descr_virtaddr[0].addr = pa1;
+		ath79_priv->dma_descr_virtaddr[0].len = mtd->writesize << 16;
+		pa2 =
+		    dma_map_single(NULL, chip->oob_poi, len - mtd->writesize,
+				   dir);
+		ath79_priv->dma_descr_virtaddr[1].addr = pa2;
+		ath79_priv->dma_descr_virtaddr[1].len =
+		    ((len - mtd->writesize) << 16) | 0x01;
+		iowrite32(ath79_priv->dma_descr_phyaddr,
+			  ath79_priv->io_base + AR934X_NAND_REG_DMA_ADDR);
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ECC_OFFSET);
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ECC_CTRL);
+		iowrite32(ath79_priv->nf_ctrl | AR934X_NAND_CTRL_CUSTOM_SIZE_EN,
+			  ath79_priv->io_base + AR934X_NAND_REG_CTRL);
+		iowrite32(len, ath79_priv->io_base + AR934X_NAND_REG_PG_SIZE);
+		dma_ctrl |= AR934X_NAND_DMA_CTRL_DMA_MODE_SG;
+		ecc_enable = 0;
+	}
+
+	if (rw) {		// read page
+		iowrite32(dma_ctrl | AR934X_NAND_DMA_CTRL_DMA_DIR_READ,
+			  ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+		iowrite32(0x30006a,
+			  ath79_priv->io_base + AR934X_NAND_REG_COMMAND);
+		ath79_priv->data_index = 0;
+	} else {		// write page
+		iowrite32(0xff00, ath79_priv->io_base + AR934X_NAND_REG_MEM_CTRL);	// Remove write protect
+		iowrite32(dma_ctrl | AR934X_NAND_DMA_CTRL_DMA_DIR_WRITE,
+			  ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+		iowrite32(0x10804c,
+			  ath79_priv->io_base + AR934X_NAND_REG_COMMAND);
+	}
+
+	while ((ioread32(ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS) &
+		AR934X_NAND_CMD_END_INT) == 0) ;
+
+	status = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+	for (i = 0; i < AR934X_NAND_STATUS_RETRY && status != 0xff; i++) {
+		udelay(2);
+		status = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+	}
+	if (status != 0xff) {
+		dev_err(ath79_priv->dev,
+			"%s: NAND status error. Status = 0x%x\n", __func__,
+			status);
+		status = -EIO;
+	} else {
+		status = 0;
+	}
+
+	if (rw) {
+		nand_wait_ready(mtd);	// wait for ready pin for read transaction
+	} else {
+		status = chip->waitfunc(mtd, chip);	// check device status for write transaction
+		if (status & NAND_STATUS_FAIL) {
+			dev_err(ath79_priv->dev,
+				"%s: Write Failed. status = 0x%x\n", __func__,
+				status);
+			status = -EIO;
+		} else {
+			status = 0;
+		}
+	}
+
+	dmastatus = ioread32(ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+	for (i = 0; i < AR934X_NAND_STATUS_RETRY && !(dmastatus & 1); i++) {
+		udelay(5);
+		dmastatus =
+		    ioread32(ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);
+	}
+	if (!(dmastatus & 1)) {
+		dev_err(ath79_priv->dev, "%s: unfinished DMA. status = 0x%x\n",
+			__func__, dmastatus);
+		ath79_nand_hw_init(ath79_priv);
+		/* is this for killing unfinished DMA ??? */
+		iowrite32(1, ath79_priv->ddr_io_addr);
+		while (ioread32(ath79_priv->ddr_io_addr) & 1) ;
+		udelay(2);
+	}
+
+	if (rw && ecc_enable) {
+		ecc_status =
+		    ioread32(ath79_priv->io_base + AR934X_NAND_REG_ECC_CTRL);
+		if (ecc_status & AR934X_NAND_ECC_ERROR) {
+			if (!ath79_page_no_ecc(mtd, page)) {
+				dev_err(ath79_priv->dev,
+					"%s: Read [%d @ 0x%x] uncorrectable errors. status = 0x%x\n",
+					__func__, len, page, ecc_status);
+				mtd->ecc_stats.failed++;
+			}
+		} else if (ecc_status & AR934X_NAND_ECC_CTRL_ERR_CORR) {
+			mtd->ecc_stats.corrected++;
+		}
+	}
+
+	if (ecc_enable)
+		dma_unmap_single(NULL, pa1, len, dir);
+	else {
+		dma_unmap_single(NULL, pa1, mtd->writesize, dir);
+		dma_unmap_single(NULL, pa2, len - mtd->writesize, dir);
+	}
+
+	if (rw && copy)		// read page
+		memcpy(buf, ath79_priv->page_buf, mtd->writesize);
+
+	iowrite32(1, ath79_priv->io_base + AR934X_NAND_REG_FIFO_INIT);
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_FIFO_INIT);
+
+	return status;
+}
+
+/****************************************/
+/***** NAND chip private APIs ***********/
+/****************************************/
+
+static void ath79_cmdfunc(struct mtd_info *mtd, unsigned int command,
+			  int column, int page_addr)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	int i, status;
+
+	ath79_priv->command = command;
+
+	switch (command) {
+
+	case NAND_CMD_STATUS:
+
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+		iowrite32(0,
+			  ath79_priv->io_base +
+			  AR934X_NAND_REG_GENERIC_SEQ_CTRL);
+		iowrite32(0x07024, ath79_priv->io_base + AR934X_NAND_REG_COMMAND);	// READ STATUS
+		while ((ioread32
+			(ath79_priv->io_base +
+			 AR934X_NAND_REG_INT_STATUS) & AR934X_NAND_CMD_END_INT)
+		       == 0) ;
+		break;
+
+	case NAND_CMD_READID:
+
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ADDR0_0);
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_ADDR0_1);
+		iowrite32(0x4, ath79_priv->io_base + AR934X_NAND_REG_PG_SIZE);
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_DMA_CTRL);	// disable DMA
+		iowrite32(ath79_priv->nf_ctrl | AR934X_NAND_CTRL_CUSTOM_SIZE_EN,
+			  ath79_priv->io_base + AR934X_NAND_REG_CTRL);
+		iowrite32(0x9021, ath79_priv->io_base + AR934X_NAND_REG_COMMAND);	// READ ID
+		while ((ioread32
+			(ath79_priv->io_base +
+			 AR934X_NAND_REG_INT_STATUS) & AR934X_NAND_CMD_END_INT)
+		       == 0) ;
+		udelay(10);
+		break;
+
+	case NAND_CMD_RESET:
+
+		dev_dbg(ath79_priv->dev, "NAND %s: Reset\n", __func__);
+
+		iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+		iowrite32(0xff00, ath79_priv->io_base + AR934X_NAND_REG_COMMAND);	// RESET
+		while ((ioread32
+			(ath79_priv->io_base +
+			 AR934X_NAND_REG_INT_STATUS) & AR934X_NAND_CMD_END_INT)
+		       == 0) ;
+		udelay(1000);
+		status = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+		for (i = 0; i < AR934X_NAND_STATUS_RETRY && status != 0xff; i++) {
+			udelay(2);
+			status =
+			    ioread32(ath79_priv->io_base +
+				     AR934X_NAND_REG_STATUS);
+		}
+		break;
+
+	default:
+		break;
+	}
+
+	ath79_priv->data_index = 0;
+
+	return;
+}
+
+static void ath79_null(struct mtd_info *mtd)
+{
+	return;
+}
+
+static int ath79_device_ready(struct mtd_info *mtd)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	int rddata;
+
+	rddata = ioread32(ath79_priv->io_base + AR934X_NAND_REG_STATUS);
+
+	return ((rddata == 0xff) ? 1 : 0);
+}
+
+static void ath79_read_buf(struct mtd_info *mtd, uint8_t * buf, int len)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	volatile int rddata, i;
+	volatile uint8_t *p = (volatile uint8_t *)&rddata;
+
+	for (i = 0; i < len; i++) {
+		if (((ath79_priv->data_index + i) % 4) == 0) {
+			rddata =
+			    le32_to_cpu(ioread32
+					(ath79_priv->io_base +
+					 AR934X_NAND_REG_FIFO_DATA));
+			if (ath79_priv->command == NAND_CMD_READID)
+				dev_dbg(ath79_priv->dev, "NAND %s: ReadID %x\n",
+					__func__, rddata);
+			ath79_priv->curr_data = rddata;
+		} else {
+			rddata = ath79_priv->curr_data;
+		}
+		buf[i] = p[(ath79_priv->data_index + i) % 4];
+		ath79_priv->data_index++;
+	}
+}
+
+static uint8_t ath79_read_byte(struct mtd_info *mtd)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+	uint8_t rdbyte;
+
+	if (ath79_priv->command == NAND_CMD_STATUS) {
+		rdbyte =
+		    ioread32(ath79_priv->io_base + AR934X_NAND_REG_RD_STATUS);
+		dev_dbg(ath79_priv->dev, "NAND: Read Status 0x%x\n", rdbyte);
+	} else {
+		ath79_read_buf(mtd, &rdbyte, 1);
+	}
+
+	return rdbyte;
+}
+
+static int ath79_block_bad(struct mtd_info *mtd, loff_t ofs, int getchip)
+{
+	struct nand_chip *chip = mtd->priv;
+	uint8_t *p = chip->oob_poi;
+
+	ath79_rw_oob(mtd, chip, 1 /*read */ , ofs >> chip->page_shift);
+
+	if (*p == 0xff)
+		return 0;
+	else
+		return 1;
+}
+
+static int ath79_read_oob(struct mtd_info *mtd, struct nand_chip *chip,
+			  int page, int sndcmd)
+{
+	ath79_rw_oob(mtd, chip, 1 /*read */ , page);
+
+	return sndcmd;
+}
+
+static int ath79_write_oob(struct mtd_info *mtd, struct nand_chip *chip,
+			   int page)
+{
+	return ath79_rw_oob(mtd, chip, 0 /*write */ , page);
+}
+
+static int ath79_read_page_raw(struct mtd_info *mtd, struct nand_chip *chip,
+			       uint8_t * buf, int page)
+{
+	return ath79_rw_page(mtd, chip, 1 /*read */ , buf,
+			     mtd->writesize + mtd->oobsize, page);
+}
+
+static int ath79_read_page(struct mtd_info *mtd, struct nand_chip *chip,
+			   uint8_t * buf, int page)
+{
+	return ath79_rw_page(mtd, chip, 1 /*read */ , buf, mtd->writesize,
+			     page);
+}
+
+static int ath79_write_page(struct mtd_info *mtd, struct nand_chip *chip,
+			    const uint8_t * buf, int page, int cached, int raw)
+{
+	int status;
+
+	if (unlikely(raw))
+		ath79_rw_page(mtd, chip, 0 /*write */ , (uint8_t *) buf,
+			      mtd->writesize + mtd->oobsize, page);
+	else {
+		if (ath79_oobbuf_is_dirty(mtd))
+			ath79_rw_oob(mtd, chip, 0 /*write */ , page);
+		ath79_rw_page(mtd, chip, 0 /*write */ , (uint8_t *) buf,
+			      mtd->writesize, page);
+	}
+
+	status = chip->waitfunc(mtd, chip);
+	if (status & NAND_STATUS_FAIL)
+		return -EIO;
+
+#ifdef CONFIG_MTD_NAND_VERIFY_WRITE
+	memset(ath79_priv->page_buf, 0, mtd->writesize);
+	ath79_rw_page(mtd, chip, 1 /*read */ , ath79_priv->page_buf,
+		      mtd->writesize, page)
+	    if (memcmp(page, ath79_priv->page_buf, mtd->writesize))
+		return -EIO;
+#endif
+	return 0;
+}
+
+static void ath79_erase_cmd(struct mtd_info *mtd, int page)
+{
+	ath79_nand_priv *ath79_priv = mtd->priv;
+
+	dev_dbg(ath79_priv->dev, "%s: page 0x%x\n", __func__, page);
+
+	iowrite32(0, ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS);
+	iowrite32(page << 16, ath79_priv->io_base + AR934X_NAND_REG_ADDR0_0);
+	iowrite32((page >> 16) & 0x0ff,
+		  ath79_priv->io_base + AR934X_NAND_REG_ADDR0_1);
+	iowrite32(0xff00, ath79_priv->io_base + AR934X_NAND_REG_MEM_CTRL);
+	iowrite32(ath79_priv->nf_ctrl,
+		  ath79_priv->io_base + AR934X_NAND_REG_CTRL);
+	iowrite32(0xd0600e, ath79_priv->io_base + AR934X_NAND_REG_COMMAND);	// block erase
+
+	while ((ioread32(ath79_priv->io_base + AR934X_NAND_REG_INT_STATUS) &
+		AR934X_NAND_CMD_END_INT) == 0) ;
+
+	return;
+}
+
+static ath_nand_vend_data_t *
+ath79_get_entry( int  *nand_id, ath_nand_vend_data_t *tbl, int count)
+{
+	int     i;
+	for (i = 0; i < count; i++, tbl ++) {
+		if ((nand_id[0] == tbl->vid) &&
+		    (nand_id[1] == tbl->did)) {
+			return tbl;
+		}
+	}
+	return NULL;
+}
+
+/****************************/
+/****** ath79_nand_remove *****/
+/****************************/
+static int ath79_nand_remove(struct platform_device *pdev)
+{
+	ath79_nand_priv *ath79_priv;
+	struct mtd_info *mtd;
+
+	mtd = (struct mtd_info *)platform_get_drvdata(pdev);
+	if (!mtd)
+		return 0;
+
+	ath79_priv = mtd->priv;
+	nand_release(mtd);
+	mtd_device_unregister(mtd);
+	dma_free_coherent(NULL, AR934X_NAND_DMA_DESCR_SIZE * 2,
+			  (void *)(ath79_priv->dma_descr_virtaddr),
+			  ath79_priv->dma_descr_phyaddr);
+	iounmap(ath79_priv->io_base);
+	iounmap(ath79_priv->ddr_io_addr);
+	kfree(ath79_priv->page_buf);
+	kfree(mtd);
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+/***************************/
+/****** ath79_nand_probe *****/
+/***************************/
+static int ath79_nand_probe(struct platform_device *pdev)
+{
+	struct resource *res;
+	struct mtd_info *mtd = NULL;
+	ath79_nand_priv *ath79_priv = NULL;
+	ath_nand_vend_data_t *entry = NULL;
+	int nandid[2];
+	int err = 0;
+
+	dev_info(&pdev->dev,
+		 DRV_DESC ", Version " DRV_VERSION
+		 " (c) 2010 Atheros Communications, Ltd.\n");
+
+	mtd = kzalloc(sizeof(*mtd) + sizeof(ath79_nand_priv), GFP_KERNEL);
+	if (!mtd) {
+		dev_err(&pdev->dev, "no memory for flash driver\n");
+		err = -ENOMEM;
+		goto out_err_kzalloc;
+	}
+
+	ath79_priv = (ath79_nand_priv *) (&mtd[1]);
+	mtd->priv = ath79_priv;
+	mtd->name = DRV_NAME;
+	mtd->owner = THIS_MODULE;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "resource missing\n");
+		err = -EINVAL;
+		goto out_err_ioremap1;
+	}
+
+	ath79_priv->dev = &(pdev->dev);
+
+	ath79_priv->io_base = ioremap(res->start, resource_size(res));
+	if (ath79_priv->io_base == NULL) {
+		dev_err(&pdev->dev, "ioremap error\n");
+		err = -EIO;
+		goto out_err_ioremap1;
+	}
+
+	ath79_priv->ddr_io_addr = ioremap(DDR_WB_FLUSH_USB_ADDRESS, 4);
+	if (ath79_priv->ddr_io_addr == NULL) {
+		dev_err(&pdev->dev, "ioremap error\n");
+		err = -EIO;
+		goto out_err_ioremap2;
+	}
+
+	ath79_priv->dma_descr_virtaddr =
+	    (void *)dma_alloc_coherent(NULL, sizeof(ath79_nand_dma_descr) * 2,
+				       &(ath79_priv->dma_descr_phyaddr),
+				       GFP_KERNEL);
+	if (ath79_priv->dma_descr_virtaddr == NULL) {
+		dev_err(&pdev->dev, "dma coherent memory alloc error\n");
+		err = -ENOMEM;
+		goto out_err_dma_alloc_coherent;
+	}
+
+	/* ath79_nand chip private functions */
+	ath79_priv->nand.cmdfunc = ath79_cmdfunc;
+	ath79_priv->nand.select_chip = (void *)ath79_null;
+	ath79_priv->nand.dev_ready = ath79_device_ready;
+	ath79_priv->nand.read_byte = ath79_read_byte;
+	ath79_priv->nand.read_buf = ath79_read_buf;
+	ath79_priv->nand.block_bad = ath79_block_bad;
+
+	/* enable flash based bad block table */
+	ath79_priv->nand.bbt_options =
+	    NAND_BBT_USE_FLASH | NAND_BBT_NO_OOB | NAND_BBT_SCAN2NDPAGE;
+
+	/* initialise the NAND controller hardware */
+	ath79_nand_hw_init(ath79_priv);
+
+	err = nand_scan_ident(mtd, 1, NULL);
+	if (err) {
+		dev_err(&pdev->dev, "nand scan identify error\n");
+		err = -ENXIO;
+		goto out_err_hw_init;
+	}
+
+	ath79_priv->page_buf = kzalloc(mtd->writesize, GFP_KERNEL);
+	if (!ath79_priv->page_buf) {
+		dev_err(&pdev->dev, "page buffer alloc error\n");
+		err = -ENOMEM;
+		goto out_err_hw_init;
+	}
+
+	/* Send the command for reading device ID */
+	ath79_priv->nand.cmdfunc(mtd, NAND_CMD_READID, 0x00, -1);
+	/* Read manufacturer and device IDs */
+	nandid[0] = ath79_priv->nand.read_byte(mtd);
+	nandid[1] = ath79_priv->nand.read_byte(mtd);
+	entry = ath79_get_entry(nandid, ath_nand_arr, NUM_ATH_NAND);
+	if(entry){
+		ath79_priv->nf_ctrl = AR934X_NAND_CTRL_ADDR_CYCLE0(entry->addrcyc);
+	}else
+		ath79_priv->nf_ctrl = AR934X_NAND_CTRL_ADDR_CYCLE0(4);
+
+	/* set nand controller page size */
+	switch (mtd->writesize) {
+	case 256:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_256;
+		break;
+	case 512:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_512;
+		break;
+	case 1024:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_1024;
+		break;
+	case 2048:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_2048;
+		break;
+	case 4096:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_4096;
+		break;
+	case 8192:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_8192;
+		break;
+	default:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_PAGE_SIZE_2048;
+		break;
+	}
+	/* set nand controller block size */
+	switch (mtd->erasesize / mtd->writesize) {
+	case 32:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_BLOCK_SIZE_32;
+		break;
+	case 64:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_BLOCK_SIZE_64;
+		break;
+	case 128:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_BLOCK_SIZE_128;
+		break;
+	case 256:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_BLOCK_SIZE_256;
+		break;
+	default:
+		ath79_priv->nf_ctrl |= AR934X_NAND_CTRL_BLOCK_SIZE_64;
+		break;
+	}
+
+	/* ath79_nand chip private ECC functions */
+	ath79_priv->nand.ecc.layout = &ath79_nand_oob_64;
+	ath79_priv->nand.ecc.mode = NAND_ECC_HW;
+	ath79_priv->nand.ecc.size = mtd->writesize;
+	ath79_priv->nand.ecc.bytes = 28;
+	ath79_priv->nand.ecc.hwctl = (void *)ath79_null;
+	ath79_priv->nand.ecc.calculate = (void *)ath79_null;
+	ath79_priv->nand.ecc.correct = (void *)ath79_null;
+	ath79_priv->nand.write_page = ath79_write_page;
+	ath79_priv->nand.ecc.write_oob = ath79_write_oob;
+	ath79_priv->nand.ecc.read_page = ath79_read_page;
+	ath79_priv->nand.ecc.read_page_raw = ath79_read_page_raw;
+	ath79_priv->nand.ecc.read_oob = ath79_read_oob;
+	ath79_priv->nand.erase_cmd = ath79_erase_cmd;
+
+	err = nand_scan_tail(mtd);
+	if (err) {
+		dev_err(&pdev->dev, "nand scan tail error %d\n", err);
+		err = -ENXIO;
+		goto out_err_nand_scan;
+	}
+
+	/* create NAND partition */
+	mtd_device_parse_register(mtd, ath79_nand_part_probes, 0,
+				  ath79_nand_partitions,
+				  ARRAY_SIZE(ath79_nand_partitions));
+
+	dev_info(&pdev->dev,
+		 "====== NAND Parameters ======\n total size = 0x%llx, page = 0x%x block = 0x%x oob = 0x%x\n",
+		 mtd->size, mtd->writesize, mtd->erasesize, mtd->oobsize);
+
+	/* save platform driver private data */
+	platform_set_drvdata(pdev, mtd);
+
+	return 0;
+
+out_err_nand_scan:
+	kfree(ath79_priv->page_buf);
+out_err_hw_init:
+	dma_free_coherent(NULL, AR934X_NAND_DMA_DESCR_SIZE * 2,
+			  (void *)ath79_priv->dma_descr_virtaddr,
+			  ath79_priv->dma_descr_phyaddr);
+out_err_dma_alloc_coherent:
+	iounmap(ath79_priv->ddr_io_addr);
+out_err_ioremap2:
+	iounmap(ath79_priv->io_base);
+out_err_ioremap1:
+	kfree(mtd);
+out_err_kzalloc:
+
+	return err;
+}
+
+static struct platform_driver ath79_nand_driver = {
+	.probe = ath79_nand_probe,
+	.remove = ath79_nand_remove,
+	.driver = {
+		   .name = DRV_NAME,
+		   .owner = THIS_MODULE,
+		   },
+};
+
+module_platform_driver(ath79_nand_driver);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR(DRV_AUTHOR);
+MODULE_DESCRIPTION(DRV_DESC);
+MODULE_ALIAS("platform:" DRV_NAME);
+
--- a/drivers/mtd/nand/Makefile
+++ b/drivers/mtd/nand/Makefile
@@ -52,6 +52,8 @@ obj-$(CONFIG_MTD_NAND_MPC5121_NFC)	+= mp
 obj-$(CONFIG_MTD_NAND_RICOH)		+= r852.o
 obj-$(CONFIG_MTD_NAND_JZ4740)		+= jz4740_nand.o
 obj-$(CONFIG_MTD_NAND_GPMI_NAND)	+= gpmi-nand/
+obj-$(CONFIG_MTD_NAND_ATH79)		+= ath79_nand.o
+obj-$(CONFIG_MTD_NAND_ATH79)		+= ath79_spinand.o
 obj-$(CONFIG_MTD_NAND_XWAY)		+= xway_nand.o
 obj-$(CONFIG_MTD_NAND_BCM47XXNFLASH)	+= bcm47xxnflash/
 
--- a/drivers/mtd/nand/Kconfig
+++ b/drivers/mtd/nand/Kconfig
@@ -556,6 +556,14 @@ config MTD_NAND_RB91X
 	tristate "NAND flash driver for the RouterBOARD 91x series"
 	depends on MTD_NAND && ATH79_MACH_RB91X
 
+config MTD_NAND_ATH79
+	tristate "NAND flash support for Qualcomm-Atheros SoCs 71xx & 93xx"
+	default n
+	depends on MTD_NAND && (SOC_AR724X || SOC_AR934X)
+	help
+	  Enables the driver for NAND flash controller on Qualcomm-Atheros System on Chips
+	  This controller is used on families AR71xx and AR9xxx.
+
 config MTD_NAND_AR934X
 	tristate "NAND flash driver for the Qualcomm Atheros AR934x/QCA955x SoCs"
 	depends on (SOC_AR934X || SOC_QCA955X)
--- /dev/null
+++ b/drivers/mtd/nand/ath79_spinand.c
@@ -0,0 +1,880 @@
+/*
+ * Copyright (c) 2015 The Linux Foundation. All rights reserved.
+ *
+ * Copyright (c) 2003-2013 Broadcom Corporation
+ *
+ * Copyright (c) 2009-2010 Micron Technology, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/nand.h>
+#include <linux/spi/spi.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <linux/mtd/mtd.h>
+
+/* cmd */
+#define CMD_READ			0x13
+#define CMD_READ_RDM			0x03
+#define CMD_PROG_PAGE_LOAD		0x02
+#define CMD_PROG_PAGE			0x84
+#define CMD_PROG_PAGE_EXC		0x10
+#define CMD_ERASE_BLK			0xd8
+#define CMD_WR_ENABLE			0x06
+#define CMD_WR_DISABLE			0x04
+#define CMD_READ_ID			0x9f
+#define CMD_RESET			0xff
+#define CMD_READ_REG			0x0f
+#define CMD_WRITE_REG			0x1f
+
+/* feature/ status reg */
+#define REG_BLOCK_LOCK			0xa0
+#define REG_OTP				0xb0
+#define REG_STATUS			0xc0
+
+/* status */
+#define STATUS_OIP_MASK			0x01
+#define STATUS_READY			(0 << 0)
+#define STATUS_BUSY			(1 << 0)
+
+#define STATUS_E_FAIL_MASK		0x04
+#define STATUS_E_FAIL			(1 << 2)
+
+#define STATUS_P_FAIL_MASK		0x08
+#define STATUS_P_FAIL			(1 << 3)
+
+#define STATUS_ECC_MASK			0x07
+#define STATUS_ECC_ERR_BITS5		0x03
+#define STATUS_ECC_ERR_BITS6		0x04
+#define STATUS_ECC_ERR_BITS7		0x05
+#define STATUS_ECC_ERR_BITS8		0x06
+#define STATUS_ECC_ERROR		0x07
+#define STATUS2ECC(status) 		(((status) >> 4) & STATUS_ECC_MASK)
+
+/* ECC/OTP enable defines */
+#define REG_ECC_MASK			0x10
+#define REG_ECC_OFF			(0 << 4)
+#define REG_ECC_ON			(1 << 4)
+
+#define REG_OTP_EN			(1 << 6)
+#define REG_OTP_PRT			(1 << 7)
+
+/* block lock */
+#define BL_ALL_UNLOCKED			0
+
+#define BLOCK_TO_RA(b)			((b) << 6)
+
+#define BUFSIZE				(10 * 64 * 2048)
+#define CACHE_BUF			2112
+
+struct ath79_spinand_info {
+	bool			init;
+	struct spi_device	*spi;
+	void			*priv;
+};
+
+struct ath79_spinand_state {
+	uint32_t	col;
+	uint32_t	row;
+	int		buf_ptr;
+	u8		*buf;
+};
+
+struct ath79_spinand_command {
+	u8		cmd;
+	u32		n_addr;		/* Number of address */
+	u8		addr[3];	/* Reg Offset */
+	u32		n_dummy;	/* Dummy use */
+	u32		n_tx;		/* Number of tx bytes */
+	u8		*tx_buf;	/* Tx buf */
+	u32		n_rx;		/* Number of rx bytes */
+	u8		*rx_buf;	/* Rx buf */
+};
+
+static const struct nand_ecclayout ath79_spinand_oob_128 = {
+	.eccbytes = 64,
+	.eccpos = {
+		64, 65, 66, 67, 68, 69, 70, 71,
+		72, 73, 74, 75, 76, 77, 78, 79,
+		80, 81, 82, 83, 84, 85, 86, 87,
+		88, 89, 90, 91, 92, 93, 94, 95,
+		96, 97, 98, 99, 100, 101, 102, 103,
+		104, 105, 106, 107, 108, 109, 110, 111,
+		112, 113, 114, 115, 116, 117, 118, 119,
+		120, 121, 122, 123, 124, 125, 126, 127},
+	.oobavail = 48,
+	.oobfree = { {.offset = 16, .length = 48}, }
+};
+
+static u8 badblock_pattern[] = { 0xff, };
+
+static struct nand_bbt_descr ath79_badblock_pattern = {
+	.options = 0,
+	.offs = 0,
+	.len = 1,
+	.pattern = badblock_pattern,
+};
+
+static inline struct ath79_spinand_state *mtd_to_state(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct ath79_spinand_info *info = (struct ath79_spinand_info *)chip->priv;
+	struct ath79_spinand_state *state = (struct ath79_spinand_state *)info->priv;
+
+	return state;
+}
+
+static int ath79_spinand_cmd(struct spi_device *spi, struct ath79_spinand_command *cmd)
+{
+	struct spi_message message;
+	struct spi_transfer x[4];
+	u8 dummy = 0xff;
+
+	spi_message_init(&message);
+	memset(x, 0, sizeof(x));
+
+	x[0].len = 1;
+	x[0].tx_buf = &cmd->cmd;
+	spi_message_add_tail(&x[0], &message);
+
+	if (cmd->n_addr) {
+		x[1].len = cmd->n_addr;
+		x[1].tx_buf = cmd->addr;
+		spi_message_add_tail(&x[1], &message);
+	}
+
+	if (cmd->n_dummy) {
+		x[2].len = cmd->n_dummy;
+		x[2].tx_buf = &dummy;
+		spi_message_add_tail(&x[2], &message);
+	}
+
+	if (cmd->n_tx) {
+		x[3].len = cmd->n_tx;
+		x[3].tx_buf = cmd->tx_buf;
+		spi_message_add_tail(&x[3], &message);
+	}
+
+	if (cmd->n_rx) {
+		x[3].len = cmd->n_rx;
+		x[3].rx_buf = cmd->rx_buf;
+		spi_message_add_tail(&x[3], &message);
+	}
+
+	return spi_sync(spi, &message);
+}
+
+static u8 ath79_spinand_id_map(struct spi_device *spi_nand, u8 device_id)
+{
+	u8 map_id;
+
+	switch (device_id) {
+	case 0xB1:
+		/* 128MiB 3,3V 16-bit */
+		map_id = 0xC1;
+		break;
+	case 0xB2:
+		/* 256MiB 3,3V 16-bit */
+		map_id = 0xCA;
+		break;
+	case 0xA1:
+		/* 128MiB 1,8V 16-bit */
+		map_id = 0xB1;
+		break;
+	case 0xA2:
+		/* 256MiB 1,8V 16-bit */
+		map_id = 0xBA;
+		break;
+	default:
+		dev_err(&spi_nand->dev, "Unknow device id %02x\n", device_id);
+		map_id = device_id;
+	}
+
+	pr_info("GD5FxGQ4x device id 0x%02x\n", device_id);
+
+	return map_id;
+}
+
+static int ath79_spinand_read_id(struct spi_device *spi_nand, u8 *id)
+{
+	int retval;
+	u8 nand_id[3];
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_READ_ID;
+	cmd.n_rx = 3;
+	cmd.rx_buf = &nand_id[0];
+
+	retval = ath79_spinand_cmd(spi_nand, &cmd);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "error %d reading id\n", retval);
+		return retval;
+	}
+
+	id[0] = nand_id[0];
+	id[1] = ath79_spinand_id_map(spi_nand, nand_id[1]);
+
+	return retval;
+}
+
+static int ath79_spinand_read_status(struct spi_device *spi_nand, uint8_t *status)
+{
+	struct ath79_spinand_command cmd = {0};
+	int ret;
+
+	cmd.cmd = CMD_READ_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_STATUS;
+	cmd.n_rx = 1;
+	cmd.rx_buf = status;
+
+	ret = ath79_spinand_cmd(spi_nand, &cmd);
+	if (ret < 0)
+		dev_err(&spi_nand->dev, "err: %d read status register\n", ret);
+
+	return ret;
+}
+
+#define MAX_WAIT_JIFFIES  (120 * HZ)
+static int __ath79_wait_till_ready(struct spi_device *spi_nand, u8 *status)
+{
+	unsigned long deadline;
+
+	deadline = jiffies + MAX_WAIT_JIFFIES;
+	do {
+		if (ath79_spinand_read_status(spi_nand, status))
+			return -1;
+		else if ((*status & STATUS_OIP_MASK) == STATUS_READY)
+			break;
+
+		cond_resched();
+	} while (!time_after_eq(jiffies, deadline));
+
+	return 0;
+}
+
+static int ath79_wait_till_ready(struct spi_device *spi_nand)
+{
+	u8 stat = 0;
+
+	if (__ath79_wait_till_ready(spi_nand, &stat))
+		return -1;
+
+	if ((stat & STATUS_OIP_MASK) == STATUS_READY)
+		return 0;
+
+	return -1;
+}
+
+static int ath79_spinand_get_otp(struct spi_device *spi_nand, u8 *otp)
+{
+	struct ath79_spinand_command cmd = {0};
+	int retval;
+
+	cmd.cmd = CMD_READ_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_OTP;
+	cmd.n_rx = 1;
+	cmd.rx_buf = otp;
+
+	retval = ath79_spinand_cmd(spi_nand, &cmd);
+	if (retval < 0)
+		dev_err(&spi_nand->dev, "error %d get otp\n", retval);
+
+	return retval;
+}
+
+static int ath79_spinand_set_otp(struct spi_device *spi_nand, u8 *otp)
+{
+	int retval;
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_WRITE_REG,
+	cmd.n_addr = 1,
+	cmd.addr[0] = REG_OTP,
+	cmd.n_tx = 1,
+	cmd.tx_buf = otp,
+
+	retval = ath79_spinand_cmd(spi_nand, &cmd);
+	if (retval < 0)
+		dev_err(&spi_nand->dev, "error %d set otp\n", retval);
+
+	return retval;
+}
+
+static int ath79_spinand_enable_ecc(struct spi_device *spi_nand)
+{
+	u8 otp = 0;
+
+	if (ath79_spinand_get_otp(spi_nand, &otp))
+		return -1;
+
+	if ((otp & REG_ECC_MASK) == REG_ECC_ON)
+		return 0;
+
+	otp |= REG_ECC_ON;
+	if (ath79_spinand_set_otp(spi_nand, &otp))
+		return -1;
+
+	return ath79_spinand_get_otp(spi_nand, &otp);
+}
+
+static int ath79_spinand_disable_ecc(struct spi_device *spi_nand)
+{
+	u8 otp = 0;
+
+	if (ath79_spinand_get_otp(spi_nand, &otp))
+		return -1;
+
+	if ((otp & REG_ECC_MASK) == REG_ECC_OFF)
+		return 0;
+
+	otp &= ~REG_ECC_MASK;
+	if (ath79_spinand_set_otp(spi_nand, &otp))
+		return -1;
+
+	return ath79_spinand_get_otp(spi_nand, &otp);
+}
+
+static int ath79_spinand_write_enable(struct spi_device *spi_nand)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_WR_ENABLE;
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_read_page_to_cache(struct spi_device *spi_nand, u32 page_id)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_READ;
+	cmd.n_addr = 3;
+	cmd.addr[0] = (u8)(page_id >> 16);
+	cmd.addr[1] = (u8)(page_id >> 8);
+	cmd.addr[2] = (u8)(page_id >> 0);
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_read_from_cache(struct spi_device *spi_nand,
+		u32 offset, u32 len, u8 *rbuf)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_READ_RDM;
+	cmd.n_addr = 3;
+	cmd.addr[0] = 0;
+	cmd.addr[1] = (u8)(offset >> 8);
+	cmd.addr[2] = (u8)(offset >> 0);
+	cmd.n_dummy = 0;
+	cmd.n_rx = len;
+	cmd.rx_buf = rbuf;
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_read_page(struct spi_device *spi_nand, u32 page_id,
+		u32 offset, u32 len, u8 *rbuf)
+{
+	int ret;
+	u8 status = 0;
+
+	ret = ath79_spinand_read_page_to_cache(spi_nand, page_id);
+	if (ret < 0) {
+		dev_err(&spi_nand->dev, "Read page to cache failed!\n");
+		return ret;
+	}
+
+	if (__ath79_wait_till_ready(spi_nand, &status)) {
+		dev_err(&spi_nand->dev, "WAIT timedout!\n");
+		return -EBUSY;
+	}
+
+	if ((status & STATUS_OIP_MASK) != STATUS_READY)
+		return -EBUSY;
+
+	if (STATUS2ECC(status) == STATUS_ECC_ERROR) {
+		struct mtd_info *mtd = dev_get_drvdata(&spi_nand->dev);
+		struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+		struct ath79_spinand_info *info = (void *)chip->priv;
+
+		/* mark the block bad in nand scan stage */
+		if (info->init) {
+			memset(rbuf, 0, len);
+			return 0;
+		}
+
+		dev_err(&spi_nand->dev,
+			"ecc error, page=%d\n", page_id);
+
+		return -1;
+	}
+
+	ret = ath79_spinand_read_from_cache(spi_nand, offset, len, rbuf);
+	if (ret < 0) {
+		dev_err(&spi_nand->dev, "read from cache failed!!\n");
+		return ret;
+	}
+
+	return ret;
+}
+
+static int ath79_spinand_program_data_to_cache(struct spi_device *spi_nand,
+		u32 offset, u32 len, u8 *wbuf)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_PROG_PAGE_LOAD;
+	cmd.n_addr = 2;
+	cmd.addr[0] = 0;
+	cmd.addr[1] = 0;;
+	cmd.n_tx = len;
+	cmd.tx_buf = wbuf;
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_program_execute(struct spi_device *spi_nand, u32 page_id)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_PROG_PAGE_EXC;
+	cmd.n_addr = 3;
+	cmd.addr[0] = (u8)(page_id >> 16);
+	cmd.addr[1] = (u8)(page_id >> 8);
+	cmd.addr[2] = (u8)(page_id >> 0);
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_program_page(struct spi_device *spi_nand,
+		u32 page_id, u32 offset, u32 len, u8 *buf)
+{
+	int retval;
+	u8 status = 0;
+	uint8_t *wbuf;
+	unsigned int i, j;
+
+	wbuf = devm_kzalloc(&spi_nand->dev, CACHE_BUF, GFP_KERNEL);
+	if (!wbuf) {
+		dev_err(&spi_nand->dev, "No memory\n");
+		return -ENOMEM;
+	}
+
+	if (ath79_spinand_read_page(spi_nand, page_id, 0, CACHE_BUF, wbuf)) {
+		devm_kfree(&spi_nand->dev, wbuf);
+		return -1;
+	}
+
+	for (i = offset, j = 0; i < len; i++, j++)
+		wbuf[i] &= buf[j];
+
+	retval = ath79_spinand_program_data_to_cache(spi_nand, offset,
+						     len, wbuf);
+
+	devm_kfree(&spi_nand->dev, wbuf);
+
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "program data to cache failed\n");
+		return retval;
+	}
+
+	retval = ath79_spinand_write_enable(spi_nand);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "write enable failed!!\n");
+		return retval;
+	}
+
+	if (ath79_wait_till_ready(spi_nand)) {
+		dev_err(&spi_nand->dev, "wait timedout!!!\n");
+		return -EBUSY;
+	}
+
+	retval = ath79_spinand_program_execute(spi_nand, page_id);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "program execute failed\n");
+		return retval;
+	}
+
+	if (__ath79_wait_till_ready(spi_nand, &status)) {
+		dev_err(&spi_nand->dev, "wait timedout!!!\n");
+		return -EBUSY;
+	}
+
+	if ((status & STATUS_OIP_MASK) != STATUS_READY)
+		return -EBUSY;
+
+	if ((status & STATUS_P_FAIL_MASK) == STATUS_P_FAIL) {
+		dev_err(&spi_nand->dev,
+			"program error, page %d\n", page_id);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int ath79_spinand_erase_block_erase(struct spi_device *spi_nand, u32 block_id)
+{
+	struct ath79_spinand_command cmd = {0};
+	u32 row = BLOCK_TO_RA(block_id);
+
+	cmd.cmd = CMD_ERASE_BLK;
+	cmd.n_addr = 3;
+	cmd.addr[0] = (u8)(row >> 16);
+	cmd.addr[1] = (u8)(row >> 8);
+	cmd.addr[2] = (u8)(row >> 0);
+
+	return ath79_spinand_cmd(spi_nand, &cmd);
+}
+
+static int ath79_spinand_erase_block(struct mtd_info *mtd,
+		struct spi_device *spi_nand, u32 page)
+{
+	int retval;
+	u8 status = 0;
+	u32 block_id = page >> (mtd->erasesize_shift - mtd->writesize_shift);
+
+	retval = ath79_spinand_write_enable(spi_nand);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "write enable failed!\n");
+		return retval;
+	}
+
+	if (ath79_wait_till_ready(spi_nand)) {
+		dev_err(&spi_nand->dev, "wait timedout!\n");
+		return -EBUSY;
+	}
+
+	retval = ath79_spinand_erase_block_erase(spi_nand, block_id);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "erase block failed!\n");
+		return retval;
+	}
+
+	if (__ath79_wait_till_ready(spi_nand, &status)) {
+		dev_err(&spi_nand->dev, "wait timedout!\n");
+		return -EBUSY;
+	}
+
+	if ((status & STATUS_OIP_MASK) != STATUS_READY)
+		return -EBUSY;
+
+	if ((status & STATUS_E_FAIL_MASK) == STATUS_E_FAIL) {
+		dev_err(&spi_nand->dev,
+			"erase error, block %d\n", block_id);
+		return -1;
+	}
+
+	return 0;
+}
+
+static void ath79_spinand_write_page_hwecc(struct mtd_info *mtd,
+		struct nand_chip *chip, const uint8_t *buf)
+{
+	chip->write_buf(mtd, buf, chip->ecc.size * chip->ecc.steps);
+}
+
+static int ath79_spinand_read_page_hwecc(struct mtd_info *mtd,
+		struct nand_chip *chip, uint8_t *buf, int page)
+{
+	u8 status;
+	uint8_t *p = buf;
+	struct ath79_spinand_info *info =
+			(struct ath79_spinand_info *)chip->priv;
+	struct spi_device *spi_nand = info->spi;
+
+	chip->read_buf(mtd, p, chip->ecc.size * chip->ecc.steps);
+
+	if (__ath79_wait_till_ready(spi_nand, &status)) {
+		dev_err(&spi_nand->dev, "wait timedout!\n");
+		return -EBUSY;
+	}
+
+	if ((status & STATUS_OIP_MASK) != STATUS_READY)
+		return -EBUSY;
+
+	if (STATUS2ECC(status) == STATUS_ECC_ERROR) {
+		pr_info("%s: ECC error\n", __func__);
+		mtd->ecc_stats.failed++;
+	} else if (STATUS2ECC(status) >= STATUS_ECC_ERR_BITS7) {
+		pr_debug("%s: ECC error %d corrected\n",
+			 __func__, STATUS2ECC(status));
+		/* mtd->ecc_stats.corrected++; */
+	}
+
+	return 0;
+}
+
+static void ath79_spinand_select_chip(struct mtd_info *mtd, int dev)
+{
+}
+
+static uint8_t ath79_spinand_read_byte(struct mtd_info *mtd)
+{
+	struct ath79_spinand_state *state = mtd_to_state(mtd);
+
+	return state->buf[state->buf_ptr++];
+}
+
+static int ath79_spinand_wait(struct mtd_info *mtd, struct nand_chip *chip)
+{
+	struct ath79_spinand_info *info = (struct ath79_spinand_info *)chip->priv;
+	unsigned long timeo = jiffies;
+	u8 status;
+
+	if (chip->state == FL_ERASING)
+		timeo += (HZ * 400) / 1000;
+	else
+		timeo += (HZ * 20) / 1000;
+
+	while (time_before(jiffies, timeo)) {
+		if (ath79_spinand_read_status(info->spi, &status))
+			return -1;
+
+		if ((status & STATUS_OIP_MASK) == STATUS_READY)
+			return 0;
+
+		cond_resched();
+	}
+	return 0;
+}
+
+static void ath79_spinand_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+	struct ath79_spinand_state *state = mtd_to_state(mtd);
+
+	memcpy(state->buf + state->buf_ptr, buf, len);
+	state->buf_ptr += len;
+}
+
+static void ath79_spinand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct ath79_spinand_state *state = mtd_to_state(mtd);
+
+	memcpy(buf, state->buf + state->buf_ptr, len);
+	state->buf_ptr += len;
+}
+
+static int ath79_init_size(struct mtd_info *mtd, struct nand_chip *this, u8 *id_data)
+{
+	mtd->oobsize		= 128;
+	mtd->writesize_shift	= 11;
+	mtd->writesize		= (1 << mtd->writesize_shift);
+	mtd->writesize_mask	= (mtd->writesize - 1);
+	mtd->erasesize_shift	= 17;
+	mtd->erasesize		= (1 << mtd->erasesize_shift);
+	mtd->erasesize_mask	= (mtd->erasesize - 1);
+
+	return NAND_BUSWIDTH_16;
+}
+
+static void ath79_spinand_reset(struct spi_device *spi_nand)
+{
+	struct ath79_spinand_command cmd = {0};
+
+	cmd.cmd = CMD_RESET;
+
+	if (ath79_spinand_cmd(spi_nand, &cmd) < 0)
+		pr_info("ath79_spinand reset failed!\n");
+
+	/* elapse 1ms before issuing any other command */
+	udelay(1000);
+
+	if (ath79_wait_till_ready(spi_nand))
+		dev_err(&spi_nand->dev, "wait timedout!\n");
+}
+
+static void ath79_spinand_cmdfunc(struct mtd_info *mtd, unsigned int command,
+		int column, int page)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct ath79_spinand_info *info = (struct ath79_spinand_info *)chip->priv;
+	struct ath79_spinand_state *state = (struct ath79_spinand_state *)info->priv;
+
+	switch (command) {
+	case NAND_CMD_READ1:
+	case NAND_CMD_READ0:
+		state->buf_ptr = 0;
+		ath79_spinand_read_page(info->spi, page, 0x0,
+					mtd->writesize + mtd->oobsize,
+					state->buf);
+		break;
+	case NAND_CMD_READOOB:
+		state->buf_ptr = 0;
+		ath79_spinand_read_page(info->spi, page, mtd->writesize,
+					mtd->oobsize, state->buf);
+		break;
+	case NAND_CMD_RNDOUT:
+		state->buf_ptr = column;
+		break;
+	case NAND_CMD_READID:
+		state->buf_ptr = 0;
+		ath79_spinand_read_id(info->spi, (u8 *)state->buf);
+		break;
+	case NAND_CMD_PARAM:
+		state->buf_ptr = 0;
+		break;
+	/* ERASE1 stores the block and page address */
+	case NAND_CMD_ERASE1:
+		ath79_spinand_erase_block(mtd, info->spi, page);
+		break;
+	/* ERASE2 uses the block and page address from ERASE1 */
+	case NAND_CMD_ERASE2:
+		break;
+	/* SEQIN sets up the addr buffer and all registers except the length */
+	case NAND_CMD_SEQIN:
+		state->col = column;
+		state->row = page;
+		state->buf_ptr = 0;
+		break;
+	/* PAGEPROG reuses all of the setup from SEQIN and adds the length */
+	case NAND_CMD_PAGEPROG:
+		ath79_spinand_program_page(info->spi, state->row, state->col,
+					   state->buf_ptr, state->buf);
+		break;
+	case NAND_CMD_STATUS:
+		ath79_spinand_get_otp(info->spi, state->buf);
+		if (!(state->buf[0] & REG_OTP_PRT))
+			state->buf[0] = REG_OTP_PRT;
+		state->buf_ptr = 0;
+		break;
+	/* RESET command */
+	case NAND_CMD_RESET:
+		if (ath79_wait_till_ready(info->spi))
+			dev_err(&info->spi->dev, "WAIT timedout!!!\n");
+
+		/* a minimum of 250us must elapse before issuing RESET cmd*/
+		udelay(250);
+		ath79_spinand_reset(info->spi);
+		break;
+	default:
+		dev_err(&mtd->dev, "Unknown CMD: 0x%x\n", command);
+	}
+}
+
+static int ath79_spinand_lock_block(struct spi_device *spi_nand, u8 lock)
+{
+	struct ath79_spinand_command cmd = {0};
+	int ret;
+
+	cmd.cmd = CMD_WRITE_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_BLOCK_LOCK;
+	cmd.n_tx = 1;
+	cmd.tx_buf = &lock;
+
+	ret = ath79_spinand_cmd(spi_nand, &cmd);
+	if (ret < 0)
+		dev_err(&spi_nand->dev, "error %d lock block\n", ret);
+
+	return ret;
+}
+
+static int ath79_spinand_probe(struct spi_device *spi_nand)
+{
+	struct mtd_info *mtd;
+	struct nand_chip *chip;
+	struct ath79_spinand_info *info;
+	struct ath79_spinand_state *state;
+
+	info  = devm_kzalloc(&spi_nand->dev, sizeof(struct ath79_spinand_info),
+			GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	info->init = true;
+	info->spi = spi_nand;
+
+	ath79_spinand_lock_block(spi_nand, BL_ALL_UNLOCKED);
+
+	state = devm_kzalloc(&spi_nand->dev, sizeof(struct ath79_spinand_state),
+			     GFP_KERNEL);
+	if (!state)
+		return -ENOMEM;
+
+	info->priv	= state;
+	state->buf_ptr	= 0;
+	state->buf	= devm_kzalloc(&spi_nand->dev, BUFSIZE, GFP_KERNEL);
+	if (!state->buf)
+		return -ENOMEM;
+
+	chip = devm_kzalloc(&spi_nand->dev, sizeof(struct nand_chip),
+			    GFP_KERNEL);
+	if (!chip)
+		return -ENOMEM;
+
+	chip->ecc.mode	= NAND_ECC_HW;
+	chip->ecc.size	= 512;
+	chip->ecc.bytes	= 16;
+	chip->ecc.strength = 8;
+	chip->ecc.layout = (void *)&ath79_spinand_oob_128;
+	chip->badblock_pattern = &ath79_badblock_pattern;
+	chip->ecc.read_page = ath79_spinand_read_page_hwecc;
+	chip->ecc.write_page = ath79_spinand_write_page_hwecc;
+
+	chip->priv	= info;
+	chip->read_buf	= ath79_spinand_read_buf;
+	chip->write_buf	= ath79_spinand_write_buf;
+	chip->read_byte	= ath79_spinand_read_byte;
+	chip->cmdfunc	= ath79_spinand_cmdfunc;
+	chip->waitfunc	= ath79_spinand_wait;
+	chip->options	|= NAND_CACHEPRG;
+	chip->select_chip = ath79_spinand_select_chip;
+	chip->init_size = ath79_init_size;
+
+	mtd = devm_kzalloc(&spi_nand->dev, sizeof(struct mtd_info), GFP_KERNEL);
+	if (!mtd)
+		return -ENOMEM;
+
+	dev_set_drvdata(&spi_nand->dev, mtd);
+
+	mtd->priv		= chip;
+	mtd->name		= dev_name(&spi_nand->dev);
+	mtd->owner		= THIS_MODULE;
+
+	if (nand_scan(mtd, 1))
+		return -ENXIO;
+
+	ath79_spinand_enable_ecc(spi_nand);
+
+	info->init = false;
+
+	return mtd_device_parse_register(mtd, NULL, NULL, NULL, 0);
+}
+
+static int ath79_spinand_remove(struct spi_device *spi)
+{
+	mtd_device_unregister(dev_get_drvdata(&spi->dev));
+
+	return 0;
+}
+
+static struct spi_driver ath79_spinand_driver = {
+	.driver = {
+		.name		= "ath79-spinand",
+		.bus		= &spi_bus_type,
+		.owner		= THIS_MODULE,
+	},
+	.probe		= ath79_spinand_probe,
+	.remove		= ath79_spinand_remove,
+};
+
+module_spi_driver(ath79_spinand_driver);
+
+MODULE_DESCRIPTION("SPI NAND driver for Giga Device");
+MODULE_LICENSE("GPL v2");
+
--- /dev/null
+++ b/arch/mips/ath79/dev-nand.c
@@ -0,0 +1,34 @@
+/*
+ *  Atheros AR71XX/AR724X/AR913X NAND controller device
+ *
+ *  Copyright (c) 2012 The Linux Foundation. All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ */
+
+#include <linux/platform_device.h>
+#include <asm/mach-ath79/ar71xx_regs.h>
+
+static struct resource ath79_nand_resources[] = {
+	{
+		.start	= AR71XX_NAND_CTRL_BASE,
+		.end	= AR71XX_NAND_CTRL_BASE + AR71XX_NAND_CTRL_SIZE - 1,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device ath79_nand_device = {
+	.name		= "ath79-nand",
+	.id		= -1,
+	.resource	= ath79_nand_resources,
+	.num_resources	= ARRAY_SIZE(ath79_nand_resources),
+};
+
+void __init ath79_register_nand(void)
+{
+	ath79_nand_device.dev.platform_data = NULL;
+	platform_device_register(&ath79_nand_device);
+}
+
--- /dev/null
+++ b/arch/mips/ath79/dev-nand.h
@@ -0,0 +1,17 @@
+/*
+ *  Atheros AR71XX/AR724X/AR913X NAND controller device
+ *
+ *  Copyright (c) 2012 The Linux Foundation. All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ */
+
+#ifndef _ATH79_DEV_NAND_H
+#define _ATH79_DEV_NAND_H
+
+void ath79_register_nand(void);
+
+#endif /* _ATH79_DEV_NAND_H */
+
--- a/arch/mips/include/asm/mach-ath79/ar71xx_regs.h
+++ b/arch/mips/include/asm/mach-ath79/ar71xx_regs.h
@@ -553,4 +553,102 @@
 #define AR934X_SRIF_DPLL2_OUTDIV_SHIFT	13
 #define AR934X_SRIF_DPLL2_OUTDIV_MASK	0x7
 
+/*
+ * NAND controller
+ */
+#define AR934X_NAND_REG_COMMAND          0x00
+#define AR934X_NAND_REG_CTRL             0x04
+#define AR934X_NAND_REG_STATUS           0x08
+#define AR934X_NAND_REG_INT_MASK         0x0c
+#define AR934X_NAND_REG_INT_STATUS       0x10
+#define AR934X_NAND_REG_ECC_CTRL         0x14
+#define AR934X_NAND_REG_ECC_OFFSET       0x18
+#define AR934X_NAND_REG_ADDR0_0          0x1c
+#define AR934X_NAND_REG_ADDR1_0          0x20
+#define AR934X_NAND_REG_ADDR0_1          0x24
+#define AR934X_NAND_REG_ADDR1_1          0x28
+#define AR934X_NAND_REG_SPARE_SIZE       0x30
+#define AR934X_NAND_REG_PROTECT          0x38
+#define AR934X_NAND_REG_LOOKUP_EN        0x40
+#define AR934X_NAND_REG_LOOKUP0          0x44
+#define AR934X_NAND_REG_LOOKUP1          0x48
+#define AR934X_NAND_REG_LOOKUP2          0x4c
+#define AR934X_NAND_REG_LOOKUP3          0x50
+#define AR934X_NAND_REG_LOOKUP4          0x54
+#define AR934X_NAND_REG_LOOKUP5          0x58
+#define AR934X_NAND_REG_LOOKUP6          0x5c
+#define AR934X_NAND_REG_LOOKUP7          0x60
+#define AR934X_NAND_REG_DMA_ADDR         0x64
+#define AR934X_NAND_REG_DMA_COUNT        0x68
+#define AR934X_NAND_REG_DMA_CTRL         0x6c
+#define AR934X_NAND_REG_MEM_CTRL         0x80
+#define AR934X_NAND_REG_PG_SIZE          0x84
+#define AR934X_NAND_REG_RD_STATUS        0x88
+#define AR934X_NAND_REG_TIME_SEQ         0x8c
+#define AR934X_NAND_REG_TIMINGS_ASYN     0x90
+#define AR934X_NAND_REG_TIMINGS_SYN      0x94
+#define AR934X_NAND_REG_FIFO_DATA        0x98
+#define AR934X_NAND_REG_TIME_MODE        0x9c
+#define AR934X_NAND_REG_DMA_ADDR_OFFSET  0xa0
+#define AR934X_NAND_REG_DMA_ADDR_OFFSET  0xa0
+#define AR934X_NAND_REG_FIFO_INIT        0xb0
+#define AR934X_NAND_REG_GENERIC_SEQ_CTRL 0xb4
+
+#define AR934X_NAND_DMA_DESCR_SIZE		8
+
+#define AR934X_NAND_TIMING_ASYN_SETTING		0x11
+#define AR934X_NAND_TIME_SEQ_SETTING		0x7fff
+#define AR934X_NAND_CTRL_CUSTOM_SIZE_EN		BIT(11)
+
+#define AR934X_NAND_CTRL_PAGE_SIZE_256		(0 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_512		BIT(8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_1024		(2 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_2048		(3 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_4096		(4 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_8192		(5 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_16384	(6 <<  8)
+#define AR934X_NAND_CTRL_PAGE_SIZE_0		(7 <<  8)
+
+#define AR934X_NAND_CTRL_BLOCK_SIZE_32		(0 <<  6)
+#define AR934X_NAND_CTRL_BLOCK_SIZE_64		BIT(6)
+#define AR934X_NAND_CTRL_BLOCK_SIZE_128		(2 <<  6)
+#define AR934X_NAND_CTRL_BLOCK_SIZE_256		(3 <<  6)
+
+#define AR934X_NAND_CTRL_ECC_EN			BIT(5)
+#define AR934X_NAND_CTRL_INT_EN			BIT(4)
+#define AR934X_NAND_CTRL_SPARE_EN		BIT(3)
+
+#define AR934X_NAND_CTRL_ADDR_CYCLE0(c)		((c) << 0)
+
+#define AR934X_NAND_DMA_CTRL_DMA_START		BIT(7)
+#define AR934X_NAND_DMA_CTRL_DMA_DIR_WRITE	(0 << 6)
+#define AR934X_NAND_DMA_CTRL_DMA_DIR_READ	BIT(6)
+#define AR934X_NAND_DMA_CTRL_DMA_MODE_SG	BIT(5)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_0	(0 << 2)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_1	BIT(2)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_2	(2 << 2)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_3	(3 << 2)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_4	(4 << 2)
+#define AR934X_NAND_DMA_CTRL_DMA_BURST_5	(5 << 2)
+#define AR934X_NAND_DMA_CTRL_ERR_FLAG		BIT(1)
+#define AR934X_NAND_DMA_CTRL_DMA_READY		BIT(0)
+
+#define AR934X_NAND_ECC_CTRL_ERR_THRESH(x)	(((x) << 8) & (0x1fu << 8))
+#define AR934X_NAND_ECC_CTRL_ECC_CAP(x)		(((x) << 5) & (0x07u << 5))
+#define AR934X_NAND_ECC_CTRL_ECC_2_BITS		AR934X_NAND_ECC_CTRL_ECC_CAP(0)
+#define AR934X_NAND_ECC_CTRL_ECC_4_BITS		AR934X_NAND_ECC_CTRL_ECC_CAP(1)
+#define AR934X_NAND_ECC_CTRL_ECC_6_BITS		AR934X_NAND_ECC_CTRL_ECC_CAP(2)
+#define AR934X_NAND_ECC_CTRL_ECC_8_BITS		AR934X_NAND_ECC_CTRL_ECC_CAP(3)
+#define AR934X_NAND_ECC_CTRL_ECC_10_BITS	AR934X_NAND_ECC_CTRL_ECC_CAP(4)
+#define AR934X_NAND_ECC_CTRL_ECC_12_BITS	AR934X_NAND_ECC_CTRL_ECC_CAP(5)
+#define AR934X_NAND_ECC_CTRL_ECC_14_BITS	AR934X_NAND_ECC_CTRL_ECC_CAP(6)
+#define AR934X_NAND_ECC_CTRL_ECC_16_BITS	AR934X_NAND_ECC_CTRL_ECC_CAP(7)
+#define AR934X_NAND_ECC_CORR_BITS(x)		(AR934X_NAND_ECC_CTRL_ERR_THRESH(x) | AR934X_NAND_ECC_CTRL_ECC_CAP(((x) / 2) - 1))
+#define AR934X_NAND_ECC_CTRL_ERR_OVER		BIT(2)
+#define AR934X_NAND_ECC_CTRL_ERR_UNCORR		BIT(1)
+#define AR934X_NAND_ECC_CTRL_ERR_CORR		BIT(0)
+#define AR934X_NAND_ECC_ERROR			(AR934X_NAND_ECC_CTRL_ERR_UNCORR | AR934X_NAND_ECC_CTRL_ERR_OVER)
+
+#define AR934X_NAND_CMD_END_INT		BIT(1)
+
 #endif /* __ASM_MACH_AR71XX_REGS_H */
